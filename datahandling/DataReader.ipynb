{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#file to read data\n",
    "import glob\n",
    "import random\n",
    "import struct \n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-3d10bb576efe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexample\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexample_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow.core.example import example_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SENTENCE_START = '<s>'\n",
    "SENTENCE_END = '</s>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD_TOKEN = '[PAD]'\n",
    "UNKNOWN_TOKEN ='[UNK]'\n",
    "START_DECODING ='[START]'\n",
    "STOP_DECODING ='[STOP]'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Vocab(object):\n",
    "  \"\"\"Vocabulary class for mapping words to integers\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-17a0dea8e1d1>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-17a0dea8e1d1>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    Args:\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "    def __init__(self, vocab_file, max_size):\n",
    "        Args:\n",
    "          vocab_file: path to the vocab file, which is assumed to contain \"<word> <frequency>\" on each line\n",
    "          max_size: integer.\n",
    "        self._word_to_id = {}\n",
    "        self._id_to_word = {}\n",
    "        self._count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-86e5678af7d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mUNKNOWN_TOKEN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPAD_TOKEN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSTART_DECODING\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSTOP_DECODING\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_word_to_id\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id_to_word\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "        for w in [UNKNOWN_TOKEN, PAD_TOKEN, START_DECODING, STOP_DECODING]:\n",
    "          self._word_to_id[w] = self._count\n",
    "          self._id_to_word[self._count] = w\n",
    "          self._count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-8-0d2ac51cbe44>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-0d2ac51cbe44>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    with open(vocab_file, 'r') as vocab_f:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#read the file\n",
    "        with open(vocab_file, 'r') as vocab_f:\n",
    "          for line in vocab_f:\n",
    "            pieces = line.split()\n",
    "            if len(pieces) != 2:\n",
    "              print 'Warning: incorrectly formatted line: %s\\n' % line\n",
    "              continue\n",
    "            w = pieces[0]\n",
    "            if w in [SENTENCE_START, SENTENCE_END, UNKNOWN_TOKEN, PAD_TOKEN, START_DECODING, STOP_DECODING]:\n",
    "              raise Exception('<s>, </s>, [UNK], [PAD], [START] and [STOP] shouldn\\'t be there, but %s is' % w)\n",
    "            if w in self._word_to_id:\n",
    "              raise Exception('Duplicated word: %s' % w)\n",
    "            self._word_to_id[w] = self._count\n",
    "            self._id_to_word[self._count] = w\n",
    "            self._count += 1\n",
    "            if max_size != 0 and self._count >= max_size:\n",
    "              print \"max_size of vocab was specified as %i; we now have %i words.\" % (max_size, self._count)\n",
    "              break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def word2id(self, word):\n",
    "        if word not in self._word_to_id:\n",
    "          return self._word_to_id[UNKNOWN_TOKEN]\n",
    "        return self._word_to_id[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def id2word(self, word_id):\n",
    "        if word_id not in self._id_to_word:\n",
    "            raise ValueError('Id not found in vocab: %d' % word_id)\n",
    "        return self._id_to_word[word_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def size(self):\n",
    "        return self._count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-26-189c66bf30a7>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-26-189c66bf30a7>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    print \"Writing word embedding metadata file to %s ...\" % (fpath)\u001b[0m\n\u001b[1;37m                                                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "    def write_metadata(self, fpath):\n",
    "        print \"Writing word embedding metadata file to %s...\" % (fpath)\n",
    "        with open(fpath, \"w\") as f:\n",
    "            fieldnames = ['word']\n",
    "            writer = csv.DictWriter(f, delimiter=\"\\t\", fieldnames=fieldnames)\n",
    "            for i in xrange(self.size()):\n",
    "                writer.writerow({\"word\": self._id_to_word[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-18-d73ff55b8a71>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-18-d73ff55b8a71>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    def article2ids(article_words, vocab):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#main function\n",
    "    def article2ids(article_words, vocab):\n",
    "        ids = []\n",
    "        oovs = []\n",
    "        unk_id = vocab.word2id(UNKNOWN_TOKEN)\n",
    "        for w in article_words:\n",
    "            i = vocab.word2id(w)\n",
    "            if i == unk_id:\n",
    "                if w not in oovs:\n",
    "                    oovs.append(w)\n",
    "                oov_num = oovs.index(w)\n",
    "                ids.append(vocab.size() + oov_num)\n",
    "            else:\n",
    "                ids.append(i)\n",
    "        return ids, oovs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def abstract2ids(abstract_words, vocab, article_oovs):\n",
    "        ids = []\n",
    "        unk_id = vocab.word2id(UNKNOWN_TOKEN)\n",
    "        for w in abstract_words:\n",
    "            i = vocab.word2id(w)\n",
    "            if i == unk_id:\n",
    "                if w in article_oovs:\n",
    "                    vocab_idx = vocab.size() + article_oovs.index(w)\n",
    "                    ids.append(vocab_idx)\n",
    "                else:\n",
    "                    ids.append(unk_id)\n",
    "            else:\n",
    "                ids.append(i)\n",
    "        return ids        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def outputids2words(id_list, vocab, article_oovs):\n",
    "        words = []\n",
    "        for i in id_list:\n",
    "            try:\n",
    "                w = vocab.id2word(i) \n",
    "            except ValueError as e: \n",
    "                    assert article_oovs is not None, \"Error: model produced a word ID that isn't in the vocabulary.\"\n",
    "                    article_oov_idx = i - vocab.size()\n",
    "                    try:\n",
    "                        w = article_oovs[article_oov_idx]\n",
    "                    except ValueError as e:\n",
    "                        raise ValueError('Error: model produced word different ID' % (i, article_oov_idx, len(article_oovs)))\n",
    "                        words.append(w)\n",
    "        return words      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def abstract2sents(abstract):\n",
    "        cur = 0\n",
    "        sents = []\n",
    "        while True:\n",
    "            try:\n",
    "                start_p = abstract.index(SENTENCE_START, cur)\n",
    "                end_p = abstract.index(SENTENCE_END, start_p + 1)\n",
    "                cur = end_p + len(SENTENCE_END)\n",
    "                sents.append(abstract[start_p+len(SENTENCE_START):end_p])\n",
    "            except ValueError as e:\n",
    "                return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def show_art_oovs(article, vocab):\n",
    "        unk_token = vocab.word2id(UNKNOWN_TOKEN)\n",
    "        words = article.split(' ')\n",
    "        words = [(\"__%s__\" % w) if vocab.word2id(w)==unk_token else w for w in words]\n",
    "        out_str = ' '.join(words)\n",
    "        return out_str     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def show_abs_oovs(abstract, vocab, article_oovs):\n",
    "        unk_token = vocab.word2id(UNKNOWN_TOKEN)\n",
    "        words = abstract.split(' ')\n",
    "        new_words = []\n",
    "        for w in words:\n",
    "            if vocab.word2id(w) == unk_token:\n",
    "                if article_oovs is None:\n",
    "                    new_words.append(\"__%s__\" % w)\n",
    "                else:\n",
    "                    if w in article_oovs:\n",
    "                        new_words.append(\"__%s__\" % w)\n",
    "                    else:\n",
    "                        new_words.append(\"!!__%s__!!\" % w)\n",
    "            else:\n",
    "                new_words.append(w)\n",
    "        out_str = ' '.join(new_words)\n",
    "        return out_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
